{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import optparse\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "sys.path.append('/n/coxfs01/cechavarria/repos/2p-pipeline/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class struct: pass\n",
    "\n",
    "opts = struct()\n",
    "opts.rootdir = '/n/coxfs01/2p-data'\n",
    "opts.animalid = 'JC110'\n",
    "opts.session = '20190909'\n",
    "opts.acquisition = 'FOV1_zoom4p0x'\n",
    "opts.traceid = 'traces102_s2p'\n",
    "opts.combined_run = 'scenes_combined'\n",
    "\n",
    "\n",
    "\n",
    "#% Set up paths:    \n",
    "acquisition_dir = os.path.join(opts.rootdir, opts.animalid, opts.session, opts.acquisition)\n",
    "\n",
    "traceid_dir = os.path.join(acquisition_dir, opts.combined_run,'traces',opts.traceid)\n",
    "\n",
    "run_dir = traceid_dir.split('/traces')[0]\n",
    "trace_arrays_dir = os.path.join(traceid_dir,'files')\n",
    "paradigm_dir = os.path.join(acquisition_dir, opts.combined_run, 'paradigm')\n",
    "\n",
    "#output directory\n",
    "responses_dir = os.path.join(acquisition_dir, opts.combined_run,'responses', opts.traceid)\n",
    "data_array_dir = os.path.join(responses_dir, 'data_arrays')\n",
    "if not os.path.exists(os.path.join(data_array_dir,'files')):\n",
    "    os.makedirs(os.path.join(data_array_dir,'files'))\n",
    "    \n",
    "if not os.path.exists(os.path.join(data_array_dir,'figures')):\n",
    "    os.makedirs(os.path.join(data_array_dir,'figures'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/coxfs01/2p-data/JC110/20190909/FOV1_zoom4p0x/scenes_combined/traces/traces102_s2p/data_arrays/processed_config_traces.hdf5\n",
      "ROIs:148\n"
     ]
    }
   ],
   "source": [
    "traceid = opts.traceid\n",
    "#% Set up paths:    \n",
    "acquisition_dir = os.path.join(opts.rootdir, opts.animalid, opts.session, opts.acquisition)\n",
    "\n",
    "traceid_dir = os.path.join(acquisition_dir, opts.combined_run,'traces', traceid)\n",
    "\n",
    "run_dir = traceid_dir.split('/traces')[0]\n",
    "trace_arrays_dir = os.path.join(traceid_dir,'files')\n",
    "paradigm_dir = os.path.join(acquisition_dir, opts.combined_run, 'paradigm')\n",
    "\n",
    "#output directory\n",
    "responses_dir = os.path.join(acquisition_dir, opts.combined_run,'responses', traceid)\n",
    "data_array_dir = os.path.join(responses_dir, 'data_arrays')\n",
    "\n",
    "if not os.path.exists(os.path.join(data_array_dir,'figures')):\n",
    "    os.makedirs(os.path.join(data_array_dir,'figures'))\n",
    "\n",
    "\n",
    "#open file to read\n",
    "data_array_fn = 'processed_config_traces.hdf5'\n",
    "data_array_filepath = os.path.join(traceid_dir, 'data_arrays', data_array_fn)\n",
    "print(data_array_filepath)\n",
    "data_grp = h5py.File(data_array_filepath, 'r')\n",
    "\n",
    "frames_tsec = data_grp.attrs['frames_tsec']\n",
    "nrois = data_grp.attrs['nrois']\n",
    "print('ROIs:%i'%(nrois))\n",
    "\n",
    "\n",
    "if 's2p_cell_rois' in data_grp.attrs.keys():\n",
    "    cell_rois = data_grp.attrs['s2p_cell_rois']\n",
    "else:\n",
    "    cell_rois = np.arange(nrois)\n",
    "\n",
    "curr_slice = 'Slice01'#hard,coding for now\n",
    "stim_period0 = data_grp.attrs['pre_frames']\n",
    "stim_period1 = data_grp.attrs['pre_frames']+data_grp.attrs['stim_frames']+1\n",
    "\n",
    "trial_fid = np.array(data_grp.attrs['trial_fid'])\n",
    "trial_run = np.array(data_grp.attrs['trial_run'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_img = np.zeros((len(data_grp[curr_slice].keys())))\n",
    "config_cond = np.zeros((len(data_grp[curr_slice].keys())))\n",
    "for cfg_count,cfg_key in enumerate(data_grp[curr_slice].keys()):\n",
    "    config_img[cfg_count] = np.array(data_grp['/'.join([curr_slice,cfg_key,'img'])])[0]+1\n",
    "    config_cond[cfg_count] = np.array(data_grp['/'.join([curr_slice,cfg_key,'scene_cond'])])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg_key = 'config000'\n",
    "cfg_count = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "motion_thresh = 5\n",
    "trial_filter = []\n",
    "for cfg_count,cfg_key in enumerate(data_grp[curr_slice].keys()):\n",
    "    motion_trace = np.array(data_grp['/'.join([cfg_key,'motion'])])\n",
    "    config_trial_filter = np.sum(np.abs(motion_trace)>motion_thresh,1)<5#keep if less than 5 frames passed threshold\n",
    "    trial_filter.append(config_trial_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 39, 40, 40, 40, 40, 40, 40, 40, 39, 39, 40, 40, 40, 40, 40, 40,\n",
       "       40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 39, 40, 40, 40, 40, 40,\n",
       "       40, 40, 39, 40, 40, 40, 40, 40, 40, 39, 40])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(trial_filter,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in greater\n",
      "  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_thresh_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cfg_key = 'config006'\n",
    "# cfg_count = 0 \n",
    "# print(np.array(data_grp[curr_slice][cfg_key]['img']))\n",
    "# print(np.array(data_grp[curr_slice][cfg_key]['scene_cond']))\n",
    "\n",
    "for cfg_count,cfg_key in enumerate(data_grp[curr_slice].keys()):\n",
    "  #  print(cfg_key)\n",
    "    motion_trace = data_grp['/'.join([cfg_key,'motion'])]\n",
    "    \n",
    "    trial_traces_f = np.array(data_grp['/'.join([curr_slice,cfg_key,'f', 'trace','np_subtracted'])])\n",
    "    trial_traces_df = np.array(data_grp['/'.join([curr_slice,cfg_key,'df', 'trace','np_subtracted'])])\n",
    "    trial_traces_df_f = np.array(data_grp['/'.join([curr_slice,cfg_key,'df_f', 'trace','np_subtracted'])])\n",
    "    trial_traces_zscore = np.array(data_grp['/'.join([curr_slice,cfg_key,'zscore', 'trace','np_subtracted'])])\n",
    "\n",
    "    trial_response_df = np.squeeze(np.mean(trial_traces_df[:,stim_period0:stim_period1,:],1))\n",
    "    trial_response_df_f = np.squeeze(np.mean(trial_traces_df_f[:,stim_period0:stim_period1,:],1))\n",
    "    trial_response_zscore = np.squeeze(np.mean(trial_traces_zscore[:,stim_period0:stim_period1,:],1))\n",
    "\n",
    "    trial_baseline_f = np.squeeze(np.mean(trial_traces_f[:,0:stim_period0,:],1))\n",
    "    trial_response_f = np.squeeze(np.mean(trial_traces_f[:,stim_period0:stim_period1,:],1))\n",
    "    trial_response_f_zscore = np.true_divide(trial_response_f-np.mean(trial_baseline_f,0),\\\n",
    "               np.std(trial_baseline_f,0))\n",
    "\n",
    "    if cfg_count == 0:\n",
    "        response_matrix_df = trial_response_df\n",
    "        response_matrix_df_f = trial_response_df_f\n",
    "        response_matrix_zscore = trial_response_zscore\n",
    "        response_matrix_f_zscore = trial_response_f_zscore\n",
    "        response_matrix_f = trial_response_f\n",
    "        baseline_matrix_f = trial_baseline_f\n",
    "    else:\n",
    "        response_matrix_df = np.dstack((response_matrix_df,trial_response_df))\n",
    "        response_matrix_df_f = np.dstack((response_matrix_df_f,trial_response_df_f))\n",
    "        response_matrix_zscore = np.dstack((response_matrix_zscore,trial_response_zscore))\n",
    "        response_matrix_f_zscore = np.dstack((response_matrix_f_zscore,trial_response_f_zscore))\n",
    "        response_matrix_f = np.dstack((response_matrix_f,trial_response_f))\n",
    "        baseline_matrix_f = np.dstack((baseline_matrix_f,trial_baseline_f))\n",
    "\n",
    "response_matrix_f = np.swapaxes(response_matrix_f,1,2) \n",
    "baseline_matrix_f = np.swapaxes(baseline_matrix_f,1,2) \n",
    "response_matrix_df = np.swapaxes(response_matrix_df,1,2) \n",
    "response_matrix_df_f = np.swapaxes(response_matrix_df_f,1,2) \n",
    "response_matrix_zscore = np.swapaxes(response_matrix_zscore,1,2) \n",
    "response_matrix_f_zscore = np.swapaxes(response_matrix_f_zscore,1,2)\n",
    "\n",
    "#perform permutation test\n",
    "nreps = 100\n",
    "ntrials,nconfigs,nrois = response_matrix_f.shape\n",
    "ks_stat = np.empty((nconfigs,nrois))\n",
    "ks_p = np.empty((nconfigs,nrois))\n",
    "perm_tstat = np.empty((nconfigs,nrois))\n",
    "perm_p = np.empty((nconfigs,nrois))\n",
    "paired_tstat = np.empty((nconfigs,nrois))\n",
    "paired_p = np.empty((nconfigs,nrois))\n",
    "simple_tstat = np.empty((nconfigs,nrois))\n",
    "simple_p = np.empty((nconfigs,nrois))\n",
    "\n",
    "for cidx in range(nconfigs):\n",
    "    for ridx in range(nrois):\n",
    "        #get true change in fluoresence\n",
    "        true_df = np.squeeze(response_matrix_df[:,cidx,ridx])\n",
    "\n",
    "        #repeat permutation a bunch of times\n",
    "        for rep in range(nreps):\n",
    "            shuffle_all = np.random.permutation(np.hstack((np.squeeze(baseline_matrix_f[:,cidx,ridx]),np.squeeze(response_matrix_f[:,cidx,ridx]))))\n",
    "\n",
    "            shuffle_base = shuffle_all[0:ntrials]\n",
    "            shuffle_stim = shuffle_all[ntrials:]\n",
    "\n",
    "            if rep == 0:\n",
    "                shuffle_df = shuffle_stim - shuffle_base\n",
    "            else:\n",
    "                shuffle_df = np.hstack((shuffle_df,shuffle_stim - shuffle_base))\n",
    "\n",
    "        #performs some stats and strone\n",
    "        ks_stat[cidx,ridx], ks_p[cidx,ridx] = stats.ks_2samp(true_df,shuffle_df)\n",
    "        perm_tstat[cidx,ridx], perm_p[cidx,ridx] = stats.ttest_ind(true_df,shuffle_df,equal_var = False)#using this test since the sampled come from same cell\n",
    "\n",
    "        #get ttest stats by comparing df distribution to 0\n",
    "        simple_tstat[cidx,ridx], simple_p[cidx,ridx] = stats.ttest_1samp(np.squeeze(response_matrix_df[:,cidx,ridx]),0)\n",
    "\n",
    "        #get ttest stats by comparing pixel values between baseline and stim period\n",
    "        paired_tstat[cidx,ridx], paired_p[cidx,ridx] = stats.ttest_rel(np.squeeze(response_matrix_f[:,cidx,ridx]),np.squeeze(baseline_matrix_f[:,cidx,ridx]))\n",
    "\n",
    "#sign your p-values\n",
    "simple_p = np.sign(simple_tstat)*simple_p\n",
    "paired_p = np.sign(paired_tstat)*paired_p\n",
    "\n",
    "#do split-half correlation to assess reliability of each cell\n",
    "nreps = 100\n",
    "\n",
    "split_size = int(np.floor(ntrials/2))\n",
    "R_cells = np.zeros((nreps,nrois))\n",
    "\n",
    "\n",
    "for rep in range(nreps):\n",
    "\n",
    "    #randomly split\n",
    "    rand_trials = np.random.permutation(ntrials)\n",
    "    half1 = response_matrix_df[rand_trials[0:split_size]]\n",
    "    half2 = response_matrix_df[rand_trials[split_size:-1]]\n",
    "\n",
    "    #get mean response across trials\n",
    "    half1_mean = np.squeeze(np.mean(half1,0))\n",
    "    half2_mean = np.squeeze(np.mean(half2,0))\n",
    "\n",
    "    #get cell split-half correlation\n",
    "    for ridx in range(nrois):\n",
    "        R_tmp = np.corrcoef(np.squeeze(half1_mean[:,ridx]),np.squeeze(half2_mean[:,ridx]))\n",
    "        R_cells[rep,ridx] = R_tmp[0,1]\n",
    "split_half_R = np.nanmean(R_cells,0)\n",
    "#save to array\n",
    "\n",
    "#open file for storage\n",
    "# Create outfile:\n",
    "resp_array_fn = 'trial_response_array.hdf5'\n",
    "resp_array_filepath = os.path.join(data_array_dir, resp_array_fn)\n",
    "print('Saving to: %s'%(resp_array_filepath))\n",
    "resp_grp = h5py.File(resp_array_filepath, 'w')\n",
    "\n",
    "#copy attributes\n",
    "for att_key in data_grp.attrs.keys():\n",
    "    resp_grp.attrs[att_key] = data_grp.attrs[att_key]\n",
    "resp_grp.attrs['config_img'] = config_img\n",
    "resp_grp.attrs['config_cond'] = config_cond\n",
    "\n",
    "data_grp.close()\n",
    "\n",
    "#save response\n",
    "f_zscore_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'f_zscore']), response_matrix_f_zscore.shape, response_matrix_f_zscore.dtype)\n",
    "f_zscore_dset[...] = response_matrix_f_zscore\n",
    "\n",
    "df_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'df']), response_matrix_df.shape, response_matrix_df.dtype)\n",
    "df_dset[...] = response_matrix_df\n",
    "\n",
    "df_f_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'df_f']), response_matrix_df_f.shape, response_matrix_df_f.dtype)\n",
    "df_f_dset[...] = response_matrix_df_f\n",
    "\n",
    "zscore_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'zscore']), response_matrix_zscore.shape, response_matrix_zscore.dtype)\n",
    "zscore_dset[...] = response_matrix_zscore\n",
    "\n",
    "kstat_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'ks_stat']), ks_stat.shape, ks_stat.dtype)\n",
    "kstat_dset[...] = ks_stat\n",
    "\n",
    "ksp_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'ks_p']), ks_stat.shape, ks_stat.dtype)\n",
    "ksp_dset[...] = ks_p\n",
    "\n",
    "perm_stat_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'perm_tstat']), perm_tstat.shape, perm_tstat.dtype)\n",
    "perm_stat_dset[...] = perm_tstat\n",
    "\n",
    "perm_p_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'perm_p']), perm_p.shape, perm_p.dtype)\n",
    "perm_p_dset[...] = perm_p\n",
    "\n",
    "simple_stat_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'simple_tstat']), simple_tstat.shape, simple_tstat.dtype)\n",
    "simple_stat_dset[...] = simple_tstat\n",
    "\n",
    "\n",
    "simple_p_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'simple_pval']), simple_p.shape, simple_p.dtype)\n",
    "simple_p_dset[...] = simple_p\n",
    "\n",
    "paired_stat_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'paired_tstat']), paired_tstat.shape, paired_tstat.dtype)\n",
    "paired_stat_dset[...] = paired_tstat\n",
    "\n",
    "\n",
    "paired_p_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'paired_pval']), paired_p.shape, paired_p.dtype)\n",
    "paired_p_dset[...] = paired_p\n",
    "\n",
    "r_dset = resp_grp.create_dataset('/'.join([curr_slice, 'responses' ,'split_half_R']), split_half_R.shape, split_half_R.dtype)\n",
    "r_dset[...] = split_half_R\n",
    "\n",
    "resp_grp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
