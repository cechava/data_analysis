{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/coxfs01/cechavarria/repos/2p-pipeline/pipeline/python/traces/utils.py:9: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-4b9461126132>\", line 2, in <module>\n",
      "    get_ipython().magic(u'matplotlib inline')\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2158, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2079, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-104>\", line 2, in matplotlib\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/magics/pylab.py\", line 100, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2949, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/IPython/core/pylabtools.py\", line 308, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 229, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/home/cesar/anaconda2/envs/pipeline/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import optparse\n",
    "import os\n",
    "import json\n",
    "import cPickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "sys.path.append('/n/coxfs01/cechavarria/repos/2p-pipeline/')\n",
    "from pipeline.python.paradigm import utils as util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class struct: pass\n",
    "\n",
    "opts = struct()\n",
    "opts.rootdir = '/n/coxfs01/2p-data'\n",
    "opts.animalid = 'JC110'\n",
    "opts.session = '20190909'\n",
    "opts.acquisition = 'FOV1_zoom4p0x'\n",
    "opts.traceid = 'traces102'\n",
    "opts.combined_run = 'scenes_combined'\n",
    "opts.run_list = ['scenes_run1','scenes_run2','scenes_run3','scenes_run4','scenes_run5','scenes_run6','scenes_run7','scenes_run8']\n",
    "\n",
    "s2p = True\n",
    "\n",
    "#Set up paths\n",
    "acquisition_dir = os.path.join(opts.rootdir, opts.animalid, opts.session, opts.acquisition)\n",
    "\n",
    "if s2p:\n",
    "    combined_traceid_file_dir = os.path.join(acquisition_dir,opts.combined_run,'traces','%s_s2p'%(opts.traceid),'files')\n",
    "else:\n",
    "    combined_traceid_file_dir = os.path.join(acquisition_dir,opts.combined_run,'traces',opts.traceid,'files')\n",
    "if not os.path.exists(combined_traceid_file_dir):\n",
    "    os.makedirs(combined_traceid_file_dir)\n",
    "    \n",
    "combined_paradigm_dir = os.path.join(acquisition_dir,opts.combined_run,'paradigm','files')\n",
    "if not os.path.exists(combined_paradigm_dir):\n",
    "    os.makedirs(combined_paradigm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenes_run1\n",
      "(300, 155, 178)\n",
      "scenes_run2\n",
      "(300, 155, 178)\n",
      "scenes_run3\n",
      "(300, 155, 178)\n",
      "scenes_run4\n",
      "(300, 155, 178)\n",
      "scenes_run5\n",
      "(300, 155, 178)\n",
      "scenes_run6\n",
      "(300, 155, 178)\n",
      "Done Combining Traces!\n",
      "Saved all info to: /n/coxfs01/2p-data/JC091/20190701/FOV1_zoom4p0x/scenes_combined/traces/traces001_s2p/files/parsedtraces.hdf5\n",
      "scenes_run1\n",
      "scenes_run2\n",
      "scenes_run3\n",
      "scenes_run4\n",
      "scenes_run5\n",
      "scenes_run6\n",
      "Combined Trial Conditions !\n",
      "Saved all info to: /n/coxfs01/2p-data/JC091/20190701/FOV1_zoom4p0x/scenes_combined/paradigm/files/trial_conditions.hdf5\n"
     ]
    }
   ],
   "source": [
    "for run_idx,run in enumerate(opts.run_list):\n",
    "    print(run)\n",
    "# run_idx = 0\n",
    "# run = 'scenes_run1'\n",
    "\n",
    "\n",
    "    #% Set up paths:   \n",
    "    if s2p:\n",
    "        traceid_dir = os.path.join(acquisition_dir, run, 'traces', '%s_s2p'%(opts.traceid))\n",
    "    else:\n",
    "        traceid_dir = util.get_traceid_from_acquisition(acquisition_dir, run, opts.traceid)\n",
    "    run_dir = traceid_dir.split('/traces')[0]\n",
    "    trace_arrays_dir = os.path.join(traceid_dir,'files')\n",
    "    paradigm_dir = os.path.join(acquisition_dir, run, 'paradigm')\n",
    "\n",
    "\n",
    "    #read file\n",
    "    parsedtraces_filepath = glob.glob(os.path.join(traceid_dir, 'files','parsedtraces*'))[0]\n",
    "    file_grp = h5py.File(parsedtraces_filepath, 'r')\n",
    "\n",
    "\n",
    "\n",
    "    curr_slice = 'Slice01'#hard-code planar data for now\n",
    "    \n",
    "    trial_fid = np.array(file_grp['Slice01']['trial_fid'])\n",
    "    trial_run = np.ones(trial_fid.shape)*(run_idx+1)\n",
    "    #get raw pixel value arrays\n",
    "    pix_raw_run = np.array(file_grp[curr_slice]['traces']['raw'])\n",
    "    pix_cell_run = np.array(file_grp[curr_slice]['traces']['np_subtracted'])\n",
    "    pix_np_run = np.array(file_grp[curr_slice]['traces']['neuropil'])\n",
    "\n",
    "    print(pix_raw_run.shape)\n",
    "\n",
    "\n",
    "\n",
    "    #save attributes and stack traces\n",
    "    if run_idx ==0:\n",
    "         # Create outfile:\n",
    "        combined_array_fn = 'parsedtraces.hdf5'\n",
    "        combined_array_filepath = os.path.join(combined_traceid_file_dir, combined_array_fn)\n",
    "        combined_grp = h5py.File(combined_array_filepath, 'w')\n",
    "        \n",
    "        combined_grp.attrs['source_dir'] = file_grp.attrs['source_dir']\n",
    "        combined_grp.attrs['framerate'] = file_grp.attrs['framerate']\n",
    "        combined_grp.attrs['volumerate'] = file_grp.attrs['volumerate']\n",
    "        combined_grp.attrs['nvolumes'] = file_grp.attrs['nvolumes']\n",
    "        combined_grp.attrs['nfiles'] = file_grp.attrs['nfiles']\n",
    "        combined_grp.attrs['iti_pre'] = file_grp.attrs['iti_pre']\n",
    "        combined_grp.attrs['iti_post'] = file_grp.attrs['iti_post']\n",
    "        combined_grp.attrs['pre_frames'] = file_grp.attrs['pre_frames']\n",
    "        combined_grp.attrs['post_frames'] = file_grp.attrs['post_frames'] \n",
    "        combined_grp.attrs['stim_frames'] = file_grp.attrs['stim_frames']\n",
    "        combined_grp.attrs['nrois'] = pix_cell_run.shape[2]\n",
    "        curr_tstamps = np.array(file_grp['Slice01']['frames_tsec'])\n",
    "        tstamps_indices = np.array(file_grp['Slice01']['frames_tsec'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        if 's2p_cell_rois' in file_grp.attrs.keys():\n",
    "            combined_grp.attrs['s2p_cell_rois'] = file_grp.attrs['s2p_cell_rois']\n",
    "\n",
    "        pix_raw_combo = pix_raw_run\n",
    "        pix_cell_combo = pix_cell_run\n",
    "        pix_np_combo = pix_np_run\n",
    "        trial_fid_combo = trial_fid\n",
    "        trial_run_combo = trial_run\n",
    "    else:\n",
    "        #for now, lop off timepoints if doesn't match what we already have, if volumerate fast enough. this is negligible\n",
    "        if pix_raw_run.shape[1]>pix_raw_combo.shape[1]:\n",
    "            extra_frames = pix_raw_run.shape[1]-pix_raw_combo.shape[1]\n",
    "            pix_raw_run = pix_raw_run[:,:-extra_frames,:]\n",
    "            pix_cell_run = pix_cell_run[:,:-extra_frames,:]\n",
    "            pix_np_run = pix_np_run[:,:-extra_frames,:]\n",
    "        \n",
    "        pix_raw_combo = np.vstack((pix_raw_combo,pix_raw_run))\n",
    "        pix_cell_combo = np.vstack((pix_cell_combo,pix_cell_run))\n",
    "        pix_np_combo = np.vstack((pix_np_combo,pix_np_run))\n",
    "        \n",
    "        trial_fid_combo = np.hstack((trial_fid_combo,trial_fid))\n",
    "        trial_run_combo = np.hstack((trial_run_combo,trial_run))\n",
    "        \n",
    "    file_grp.close()\n",
    "\n",
    "#save combined traces to file\n",
    "#save arrays to file\n",
    "\n",
    "fset = combined_grp.create_dataset('/'.join([curr_slice, 'frames_tsec']), curr_tstamps.shape, curr_tstamps.dtype)\n",
    "fset[...] = curr_tstamps\n",
    "\n",
    "tset = combined_grp.create_dataset('/'.join([curr_slice, 'frames_indices']), tstamps_indices.shape, tstamps_indices.dtype)\n",
    "tset[...] = tstamps_indices \n",
    "\n",
    "fidset = combined_grp.create_dataset('/'.join([curr_slice, 'trial_fid']), trial_fid_combo.shape, trial_fid_combo.dtype)\n",
    "fidset[...] = trial_fid_combo\n",
    "\n",
    "runset = combined_grp.create_dataset('/'.join([curr_slice, 'trial_run']), trial_run_combo.shape, trial_run_combo.dtype)\n",
    "runset[...] = trial_run_combo\n",
    "\n",
    "raw_combined = combined_grp.create_dataset('/'.join([curr_slice, 'traces', 'raw']), pix_raw_combo.shape, pix_raw_combo.dtype)\n",
    "raw_combined[...] = pix_raw_combo\n",
    "\n",
    "cell_combined = combined_grp.create_dataset('/'.join([curr_slice, 'traces', 'np_subtracted']), pix_cell_combo.shape, pix_cell_combo.dtype)\n",
    "cell_combined[...] = pix_cell_combo\n",
    "\n",
    "np_combined = combined_grp.create_dataset('/'.join([curr_slice, 'traces', 'neuropil']), pix_np_combo.shape, pix_np_combo.dtype)\n",
    "np_combined[...] = pix_np_combo\n",
    "\n",
    "combined_grp.close()\n",
    "\n",
    "print('Done Combining Traces!')\n",
    "print('Saved all info to: %s'%(combined_array_filepath))\n",
    "\n",
    "#for run in runlist\n",
    "for run_idx,run in enumerate(run_list):\n",
    "    print(run)\n",
    "# run = 'scenes_run1'\n",
    "# run_idx = 0\n",
    "\n",
    "    #open stimulus condition file\n",
    "    stimconfig_fn = 'trial_conditions.hdf5'\n",
    "    paradigm_dir = os.path.join(acquisition_dir, run, 'paradigm')\n",
    "    stimconfig_filepath = os.path.join(paradigm_dir, 'files', stimconfig_fn)\n",
    "    run_config_grp = h5py.File(stimconfig_filepath, 'r')\n",
    "\n",
    "    config_run = np.array(run_config_grp['trial_config'])\n",
    "    cond_run = np.array(run_config_grp['trial_cond'])\n",
    "    img_run = np.array(run_config_grp['trial_img'])\n",
    "\n",
    "    if run_idx ==0:\n",
    "        #open output file\n",
    "        combo_config_filepath = os.path.join(combined_paradigm_dir, stimconfig_fn)\n",
    "        combo_config_grp = h5py.File(combo_config_filepath, 'w')\n",
    "\n",
    "        combo_config_grp.attrs['ntrials'] = run_config_grp.attrs['ntrials']\n",
    "\n",
    "        config_combo = config_run\n",
    "        cond_combo = cond_run\n",
    "        img_combo = img_run\n",
    "    else:\n",
    "        config_combo = np.hstack((config_combo,config_run))\n",
    "        cond_combo = np.hstack((cond_combo,config_run))\n",
    "        img_combo = np.hstack((img_combo,config_run))\n",
    "\n",
    "    run_config_grp.close()\n",
    "\n",
    "print('Combined Trial Conditions !')\n",
    "\n",
    "\n",
    "\n",
    "#save arrays to file\n",
    "imgcombo = combo_config_grp.create_dataset('trial_img', img_combo.shape, img_combo.dtype)\n",
    "imgcombo[...] = img_combo\n",
    "\n",
    "configcombo = combo_config_grp.create_dataset('trial_config', config_combo.shape, config_combo.dtype)\n",
    "configcombo[...] = config_combo\n",
    "\n",
    "condcombo = combo_config_grp.create_dataset('trial_cond', cond_combo.shape, cond_combo.dtype)\n",
    "condcombo[...] = cond_combo\n",
    "\n",
    "combo_config_grp.close()\n",
    "print('Saved all info to: %s'%(combo_config_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,\n",
       "        6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  6.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_config_grp.close()\n",
    "combo_config_grp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pix_raw_combo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combine paradigm info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pix_raw_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if pix_raw_run.shape[1]>pix_raw_combo.shape[1]:\n",
    "    extra_frames = pix_raw_run.shape[1]-pix_raw_combo.shape[1]\n",
    "    pix_raw_run = pix_raw_run[:,:-extra_frames,:]\n",
    "    pix_cell_run = pix_cell_run[:,:-extra_frames,:]\n",
    "    pix_np_run = pix_np_run[:,:-extra_frames,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_grp.close()\n",
    "combined_grp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
